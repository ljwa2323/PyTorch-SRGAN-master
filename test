#!/usr/bin/env python

import argparse
import os
ROOT = os.path.abspath('.')
import sys
import torch

import torch.nn as nn
from torch.autograd import Variable
from torch.utils.data import Dataset, DataLoader
import torchvision
import torchvision.datasets as datasets
from torchvision.utils import save_image

from models import Generator, Discriminator, FeatureExtractor
from utils import Visualizer, normalize, rev_normalize, stat

import numpy as np
import matplotlib.pyplot as plt

import skimage

datas = np.load(os.path.join(ROOT, 'datas/datas.npz'))

parser = argparse.ArgumentParser()
parser.add_argument('--dataset', type=str, default='high vs low resolution image', help='dataset name')
# parser.add_argument('--dataroot', type=str, default='./data', help='path to dataset')
# parser.add_argument('--workers', type=int, default=2, help='number of data loading workers')
parser.add_argument('--batchSize', type=int, default=10, help='input batch size')
parser.add_argument('--imageSize', type=int, default=16, help='the low resolution image size')
parser.add_argument('--upSampling', type=int, default=4, help='low to high resolution scaling factor')
parser.add_argument('--cuda', action='store_true', help='enables cuda')
# parser.add_argument('--nGPU', type=int, default=1, help='number of GPUs to use')
parser.add_argument('--generatorWeights', type=str, default='checkpoints/generator_final.pth',
                    help="path to generator weights (to continue training)")
parser.add_argument('--discriminatorWeights', type=str, default='checkpoints/discriminator_final.pth',
                    help="path to discriminator weights (to continue training)")

opt = parser.parse_args()
print(opt)

# try:
#     os.makedirs('output/high_res_fake')
#     os.makedirs('output/high_res_real')
#     os.makedirs('output/low_res')
# except OSError:
#     pass

if torch.cuda.is_available() and not opt.cuda:
    print("WARNING: You have a CUDA device, so you should probably run with --cuda")


class Mydata(Dataset):
    def __init__(self, datas):
        hf_data, lf_data = datas['hf'], datas['lf']
        hf_data, hf_mi, hf_ma = normalize(hf_data)
        lf_data, lf_mi, lf_ma = normalize(lf_data)

        self.datas = {"hf":hf_data, "lf":lf_data}
        self.datas_attr = {"hf_mi" : hf_mi,
                           "hf_ma" : hf_ma,
                           "lf_mi": lf_mi,
                           "lf_ma": lf_ma}

    def __getitem__(self, item):

        # return [self.datas['hf'][item], self.datas['lf'][item]]
        return [{"data": [self.datas['hf'][item],
                         self.datas['lf'][item]],
                "attr":[self.datas_attr['hf_mi'][item],
                        self.datas_attr['hf_ma'][item],
                        self.datas_attr['lf_mi'][item],
                        self.datas_attr['lf_ma'][item]]}]

    def __len__(self):
        assert len(self.datas['hf']) == len(self.datas['lf'])
        return len(self.datas['hf'])

datasets = Mydata(datas)

dataloader = DataLoader(datasets, batch_size=opt.batchSize, shuffle=True, num_workers=0)

generator = Generator(10, 4)
if opt.generatorWeights != '':
    generator.load_state_dict(torch.load(opt.generatorWeights))
print(generator)

discriminator = Discriminator()
if opt.discriminatorWeights != '':
    discriminator.load_state_dict(torch.load(opt.discriminatorWeights))
print(discriminator)

# For the content loss
feature_extractor = FeatureExtractor(torchvision.models.vgg19(pretrained=True))
print(feature_extractor)
content_criterion = nn.MSELoss()
adversarial_criterion = nn.BCELoss()

target_real = Variable(torch.ones(opt.batchSize, 1))
target_fake = Variable(torch.zeros(opt.batchSize, 1))

# if gpu is to be used
if opt.cuda:
    generator.cuda()
    discriminator.cuda()
    feature_extractor.cuda()
    content_criterion.cuda()
    adversarial_criterion.cuda()
    target_real = target_real.cuda()
    target_fake = target_fake.cuda()

low_res = torch.FloatTensor(opt.batchSize, 3, opt.imageSize, opt.imageSize)

print('Test started...')
mean_generator_content_loss = 0.0
mean_generator_adversarial_loss = 0.0
mean_generator_total_loss = 0.0
mean_discriminator_loss = 0.0

# Set evaluation mode (not training)
generator.eval()
discriminator.eval()


psnr = 0
ssim = 0
count = 0
gen_pics = []
for i, data in enumerate(dataloader):
    # Generate data
    high_res_real, low_res = data[0]['data'][0], data[0]['data'][1]
    high_res_real = high_res_real.to(torch.float32)
    low_res = low_res.to(torch.float32)

    hf_mi, hf_ma, lf_mi, lf_ma = data[0]['attr'][0], data[0]['attr'][1], data[0]['attr'][2], data[0]['attr'][3]

    # Generate real and fake inputs
    if opt.cuda:
        high_res_real = Variable(high_res_real.cuda())
        high_res_fake = generator(Variable(low_res).cuda())
    else:
        high_res_real = Variable(high_res_real)
        high_res_fake = generator(Variable(low_res))

    ######### Test discriminator #########

    discriminator_loss = adversarial_criterion(discriminator(high_res_real), target_real) + \
                         adversarial_criterion(discriminator(Variable(high_res_fake.data)), target_fake)
    mean_discriminator_loss += discriminator_loss.data

    ######### Test generator #########

    real_features = Variable(feature_extractor(high_res_real).data)
    fake_features = feature_extractor(high_res_fake)

    generator_content_loss = content_criterion(high_res_fake, high_res_real) + 0.006 * content_criterion(fake_features,
                                                                                                         real_features)
    mean_generator_content_loss += generator_content_loss.data
    generator_adversarial_loss = adversarial_criterion(discriminator(high_res_fake), target_real)
    mean_generator_adversarial_loss += generator_adversarial_loss.data

    generator_total_loss = generator_content_loss + 1e-3 * generator_adversarial_loss
    mean_generator_total_loss += generator_total_loss.data

    ######### Status and display #########
    sys.stdout.write('\r[%d/%d] Discriminator_Loss: %.4f Generator_Loss (Content/Advers/Total): %.4f/%.4f/%.4f' % (
    i, len(dataloader),
    discriminator_loss.data, generator_content_loss.data, generator_adversarial_loss.data,
    generator_total_loss.data))

    high_res_real = rev_normalize(high_res_real.cpu().data, hf_mi.to(torch.float32), hf_ma.to(torch.float32))
    high_res_fake = rev_normalize(high_res_fake.cpu().data, hf_mi.to(torch.float32), hf_ma.to(torch.float32))
    low_res = rev_normalize(low_res.data, lf_mi.to(torch.float32), lf_ma.to(torch.float32))

    high_res_real = high_res_real.transpose((0, 2, 3, 1))
    high_res_fake = high_res_fake.transpose((0, 2, 3, 1))
    low_res = low_res.transpose((0, 2, 3, 1))

    gen_pics.append(high_res_fake)

    count += high_res_fake.shape[0]

    for j in range(opt.batchSize):
        psnr += skimage.measure.compare_psnr(high_res_fake[j], high_res_real[j])
        ssim += skimage.measure.compare_ssim(high_res_fake[j], high_res_real[j], multichannel=True)
    #     plt.subplot(1, 3, 1), plt.imshow(high_res_real[j]),
    #     plt.subplot(1, 3, 2), plt.imshow(high_res_fake[j]),
    #     plt.subplot(1, 3, 3), plt.imshow(low_res[j]),
    #     plt.savefig('output/test/' + str(i * opt.batchSize + j) + '.png')

        # save_image(high_res_real[j], 'output/high_res_real/' + str(i * opt.batchSize + j) + '.png')
        # save_image(high_res_fake[j], 'output/high_res_fake/' + str(i * opt.batchSize + j) + '.png')
        # save_image(low_res[j], 'output/low_res/' + str(i * opt.batchSize + j) + '.png')

sys.stdout.write(
    '\r[%d/%d] Discriminator_Loss: %.4f Generator_Loss (Content/Advers/Total): %.4f/%.4f/%.4f\n' % (i, len(dataloader),
                                                                                                    mean_discriminator_loss / len(
                                                                                                        dataloader),
                                                                                                    mean_generator_content_loss / len(
                                                                                                        dataloader),
                                                                                                    mean_generator_adversarial_loss / len(
                                                                                                        dataloader),
                                                                                                    mean_generator_total_loss / len(
                                                                                                        dataloader)))

sys.stdout.write('The average psnr: %.2f   ssim: %.2f\n'%(psnr/count, ssim/count))

gen_pics = np.concatenate(gen_pics, axis=0)
np.savetxt('new data/1_channel.csv',gen_pics[...,0].reshape(-1, 1))
np.savetxt('new data/2_channel.csv',gen_pics[...,1].reshape(-1, 1))
np.savetxt('new data/3_channel.csv',gen_pics[...,2].reshape(-1, 1))
